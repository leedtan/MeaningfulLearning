{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "class_names=os.listdir('train')\n",
    "from tensorflow.keras.models import load_model\n",
    "class model:\n",
    "    def __init__(self):\n",
    "        self.model = load_model('class2')\n",
    "    def predict(self, image):\n",
    "        pred_vec=self.model.predict(image)\n",
    "        return class_names[np.argmax(pred_vec)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling(image_directory='images', initial_epochs=1, fine_tune_epochs=1,\n",
    "             base_learning_rate = 0.0001):\n",
    "    train_dir = \"train\"\n",
    "    validation_dir = \"test\"\n",
    "\n",
    "    BATCH_SIZE = 32\n",
    "    IMG_SIZE = (64, 64)\n",
    "\n",
    "    train_dataset = image_dataset_from_directory(\n",
    "        train_dir,label_mode='categorical', shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE\n",
    "    )\n",
    "\n",
    "\n",
    "    validation_dataset = image_dataset_from_directory(\n",
    "        validation_dir,label_mode='categorical', shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE\n",
    "    )\n",
    "\n",
    "\n",
    "    class_names = train_dataset.class_names\n",
    "\n",
    "    val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "    test_dataset = validation_dataset.take(val_batches // 5)\n",
    "    validation_dataset = validation_dataset.skip(val_batches // 5)\n",
    "\n",
    "\n",
    "    data_augmentation = tf.keras.Sequential(\n",
    "        [\n",
    "             tf.keras.layers.experimental.preprocessing.RandomFlip(\"vertical\"),\n",
    "             tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "    rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1.0 / 127.5, offset=-1)\n",
    "\n",
    "    IMG_SHAPE = IMG_SIZE + (3,)\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights=\"imagenet\")\n",
    "\n",
    "    image_batch, label_batch = next(iter(train_dataset))\n",
    "    feature_batch = base_model(image_batch)\n",
    "    print(feature_batch.shape)\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    feature_batch_average = global_average_layer(feature_batch)\n",
    "\n",
    "    prediction_layer = tf.keras.layers.Dense(len(class_names))\n",
    "    prediction_batch = prediction_layer(feature_batch_average)\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(64, 64, 3))\n",
    "    x = data_augmentation(inputs)\n",
    "    x = preprocess_input(x)\n",
    "    x = base_model(x, training=False)\n",
    "    x = global_average_layer(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    outputs = prediction_layer(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    \n",
    "    history = model.fit(train_dataset, epochs=initial_epochs, validation_data=validation_dataset)\n",
    "\n",
    "    base_model.trainable = True\n",
    "\n",
    "    fine_tune_at = 100\n",
    "\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate / 10),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    total_epochs = initial_epochs + fine_tune_epochs\n",
    "    history_fine = model.fit(\n",
    "        train_dataset, epochs=total_epochs, initial_epoch=history.epoch[-1], validation_data=validation_dataset\n",
    "    )\n",
    "    \n",
    "    model.save('class2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4800 files belonging to 4 classes.\n",
      "Found 1600 files belonging to 4 classes.\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "(32, 2, 2, 1280)\n",
      "150/150 [==============================] - 67s 353ms/step - loss: 1.9933 - accuracy: 0.3007 - val_loss: 1.0972 - val_accuracy: 0.5758\n",
      "Epoch 1/2\n",
      "150/150 [==============================] - 91s 449ms/step - loss: 1.0153 - accuracy: 0.6010 - val_loss: 0.4545 - val_accuracy: 0.8117\n",
      "Epoch 2/2\n",
      "150/150 [==============================] - 67s 441ms/step - loss: 0.5992 - accuracy: 0.7533 - val_loss: 0.3681 - val_accuracy: 0.8445\n",
      "INFO:tensorflow:Assets written to: class2\\assets\n"
     ]
    }
   ],
   "source": [
    "modeling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.load_model('class2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.1758766,  4.0067916, -3.075168 , -8.931844 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "img=image.load_img('train/bird/1001_128.jpg', target_size=(64, 64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['berry', 'bird', 'dog', 'flower']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4800 files belonging to 4 classes.\n",
      "Found 1600 files belonging to 4 classes.\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "(32, 2, 2, 1280)\n",
      "150/150 [==============================] - 40s 236ms/step - loss: 2.2094 - accuracy: 0.2876 - val_loss: 1.2143 - val_accuracy: 0.5180\n",
      "Epoch 1/2\n",
      "150/150 [==============================] - 44s 250ms/step - loss: 1.0902 - accuracy: 0.5742 - val_loss: 0.4315 - val_accuracy: 0.8328\n",
      "Epoch 2/2\n",
      "150/150 [==============================] - 37s 242ms/step - loss: 0.6020 - accuracy: 0.7516 - val_loss: 0.3479 - val_accuracy: 0.8758\n",
      "INFO:tensorflow:Assets written to: class2\\assets\n"
     ]
    }
   ],
   "source": [
    "modeling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "transfer_learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
