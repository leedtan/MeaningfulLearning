{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make sure you are on track, I put together a baseline approach where I \n",
    "# apply parameter sharing and local connections to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets grabbed from https://www.kaggle.com/borismarjanovic/price-volume-data-for-all-us-stocks-etfs\n",
    "# Let's look at the problem of forecasting stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import one of the datasets from the link.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('aadr.us.csv')\n",
    "\n",
    "numeric_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize some of our data.\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure(data=[go.Candlestick(x=df.index[:100],\n",
    "                open=df['Open'][:100],\n",
    "                high=df['High'][:100],\n",
    "                low=df['Low'][:100],\n",
    "                close=df['Close'][:100])])\n",
    "fig.update_layout(\n",
    "    title= {\n",
    "        'text': '',\n",
    "      'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'},\n",
    "      font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=20,\n",
    "        color=\"#7f7f7f\"\n",
    "    )\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = df.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_date = x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_y(df):\n",
    "    y_future = df[['High', 'Low']].mean(1).iloc[1:].values\n",
    "    y_past = df['Close'].iloc[:-1].values\n",
    "    y_diff = (y_future - y_past)/y_past\n",
    "    return y_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn, x_val = x.iloc[:np.floor(n_date * .8).astype(int)+1], x.iloc[np.floor(n_date * .8).astype(int):]\n",
    "y_trn, y_val = [calc_y(x_set) for x_set in (x_trn, x_val)]\n",
    "mean_vals = x_trn[numeric_cols].mean().mean()\n",
    "x_trn = x_trn / mean_vals\n",
    "x_val = x_val / mean_vals\n",
    "x_trn, x_val = x_trn[:-1], x_val[:-1]\n",
    "x_trn, x_val = x_trn.values, x_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, LeakyReLU, Flatten, Dense\n",
    "tfph = tf.compat.v1.placeholder\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "xph = tfph(tf.float32, shape = (None, None, 5))\n",
    "relu = LeakyReLU()\n",
    "yph = tfph(tf.float32, shape = (None, None,))\n",
    "hidden_size = 256\n",
    "lstm = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "hidden = lstm(xph)\n",
    "lstm2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "hidden = lstm2(hidden)\n",
    "lstm3 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "hidden = lstm3(hidden)\n",
    "lstm4 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "output = lstm4(hidden)\n",
    "\n",
    "flattened = Flatten()(yph)\n",
    "# yhat = Dense(10)(yph)\n",
    "yhat = tf.reduce_mean(output, 2)\n",
    "yhat_last = yhat[:,-1]\n",
    "loss = tf.reduce_mean(tf.square(yph[:,3:] - yhat[:,3:]))\n",
    "# loss =tf.reduce_mean((yhat - ytrn)**2)\n",
    "opt = tf.compat.v1.train.AdamOptimizer(learning_rate=1e-6).minimize(loss)\n",
    "sess = tf.compat.v1.Session()\n",
    "sess.run(tf.compat.v1.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_samples(x, length = 6):\n",
    "    x_max = x.shape[0] - length\n",
    "    x_samples = np.stack([x[start:start + length] for start in range(x_max)], 0)\n",
    "    return x_samples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "def get_samples(x, y, length = 10):\n",
    "    x_min = 0\n",
    "    x_max = x.shape[0] - length\n",
    "    starts = np.random.randint(x_min, x_max, size = 8)\n",
    "    x_stacked = np.stack([x[start:start + length] for start in starts], axis=0)\n",
    "    y_stacked = np.stack([y[start:start + length] for start in starts], axis=0)\n",
    "    return x_stacked, y_stacked\n",
    "for i in range(1000):\n",
    "    x_sample, y_sample = get_samples(x_trn, y_trn)\n",
    "    _, l2 = sess.run([opt, loss], {xph:x_sample, yph:y_sample})\n",
    "    if i % 100 == 0:\n",
    "        x_all_samples = get_all_samples(x_trn)\n",
    "        yhat_pred = sess.run(yhat_last, {xph:x_all_samples})\n",
    "        corr = np.corrcoef(yhat_pred, y_trn[:-6])[1,0]\n",
    "        print('corr',corr, 'trn loss', l2)\n",
    "        \n",
    "        \n",
    "        x_sample, y_sample = get_samples(x_val, y_val)\n",
    "        l2_val = sess.run(loss, {xph:x_sample, yph:y_sample})\n",
    "        x_all_samples_val = get_all_samples(x_val)\n",
    "        yhat_pred_val = sess.run(yhat_last, {xph:x_all_samples_val})\n",
    "        corr_val = np.corrcoef(yhat_pred_val, y_val[:-6])[1,0]\n",
    "        print('corr_val',corr_val, 'val loss', l2_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
