{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Today we will look at hands on feature generation,\n",
    "# regularization, model development, and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import os\n",
    "imgdir = 'output_images'\n",
    "if not os.path.isdir(imgdir):\n",
    "    os.mkdir(imgdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlbl = 'bananas bought'\n",
    "ylbl = 'bananas sold'\n",
    "NUM_DATA = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_y(x):\n",
    "    y = x + np.random.randint(-3, 3, size=(len(x), 1)) - x **2 / 150 - (x > 40) * 10 - (x < 30) * 10\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "x = np.random.randint(20, 50, size=(NUM_DATA, 1))\n",
    "y = get_y(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(x.flatten(), y.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data():\n",
    "    # Write a function that plots the data. \n",
    "    # Include axis labels and a title\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(x, y, label='real sales')\n",
    "    plt.xlabel(xlbl)\n",
    "    plt.ylabel(ylbl)\n",
    "    plt.title('store banana sales vs received')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data()\n",
    "plt.savefig(os.path.join(imgdir, 'raw_data.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr = # TODO: Train a Ridge model from the x, y data\n",
    "\n",
    "lr.coef_, lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizx = # TODO: Create a much more granular dataset of the values of x from below the minimum value\n",
    "# to above the maximum value. This will be used to visualize what the model is learning\n",
    "\n",
    "lry = lr.predict(vizx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data()\n",
    "# TODO: plot the new visualization data in red. Give it a label, and add a legend to the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat8 = # TODO: Create a polynomial feature expansion of the real dataset.\n",
    "# Normalize each of the features by making them have mean 0 and standard deviation 1\n",
    "\n",
    "vizx8 = # TODO: Apply the same transformation to vizx. Calculating the polynomial\n",
    "# features and normalizing them\n",
    "\n",
    "lr8 = # TODO train a model with these new features. use Ridge(0) to not apply regularization\n",
    "lr8y = lr8.predict(vizx8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'The model learned y = ' + ' + '.join([str(t[0]) + ' * ' + str(t[1].round(2)) \n",
    "            for t in list(zip(['x^' + str(idx) for idx in range(1, 9)], \n",
    "      (lr8.coef_[:,1:] * mean[1:]).flatten()))]) + ' + ' + str(lr8.intercept_[0].round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr8.coef_, lr8.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = 3\n",
    "plot_data()\n",
    "# TODO: Plot vixz and lr8y.\n",
    "# add buffer to the left and right of the graph to make it easier to view.\n",
    "plt.xlim(x.min() - buffer, x.max() + buffer)\n",
    "plt.ylim(y.min() - buffer * 2, y.max() + buffer * 2)\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(imgdir, 'degree8_predictions.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr8.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "regs = # Train a new model with Ridge(10) to have a regularization coefficient of 10.\n",
    "ystrong = regs.predict(vizx8)\n",
    "\n",
    "plot_data()\n",
    "plt.plot(vizx, ystrong, c='red', label='strong regularization')\n",
    "plt.xlim(x.min() - buffer, x.max() + buffer)\n",
    "plt.ylim(y.min() - buffer * 2, y.max() + buffer * 2)\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(imgdir, 'strongreg_predictions.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'The model learned y = ' + ' + '.join([str(t[0]) + ' * ' + str(t[1].round(2)) \n",
    "            for t in list(zip(['x^' + str(idx) for idx in range(1, 9)], \n",
    "                              (regs.coef_[:,1:] * mean[1:]).flatten()))]) + ' + ' + str(regs.intercept_[0].round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Thought process. \n",
    "# Were the parameters the model learned larger or smaller than without regularization? \n",
    "# By what factor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "regm = # Train a new model with regularization 1e-5\n",
    "ymed = regm.predict(vizx8)\n",
    "\n",
    "plot_data()\n",
    "plt.plot(vizx, ymed, c='red', label='medium regularization')\n",
    "plt.xlim(x.min() - buffer, x.max() + buffer)\n",
    "plt.ylim(y.min() - buffer * 2, y.max() + buffer * 2)\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(imgdir, 'medium_reg_predictions.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'The model learned y = ' + ' + '.join([str(t[0]) + ' * ' + str(t[1].round(2)) \n",
    "            for t in list(zip(['x^' + str(idx) for idx in range(1, 9)], \n",
    "                              (regm.coef_[:,1:] * mean[1:]).flatten()))]) + ' + ' + str(regm.intercept_[0].round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "regl = # Train a new model with regularization 1e-20\n",
    "ylight = regl.predict(vizx8)\n",
    "\n",
    "plot_data()\n",
    "plt.plot(vizx, ylight, c='red', label='light regularization')\n",
    "plt.xlim(x.min() - buffer, x.max() + buffer)\n",
    "plt.ylim(y.min() - buffer * 2, y.max() + buffer * 2)\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(imgdir, 'lightreg_predictions.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'The model learned y = ' + ' + '.join([str(t[0]) + ' * ' + str(t[1].round(2)) \n",
    "            for t in list(zip(['x^' + str(idx) for idx in range(1, 9)], \n",
    "                              (regl.coef_[:,1:] * mean[1:]).flatten()))]) + ' + ' + str(regl.intercept_[0].round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(figsize=(10,4)):\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.scatter(x, y, label='real sales')\n",
    "    plt.xlabel(xlbl)\n",
    "    plt.ylabel(ylbl)\n",
    "    plt.title('store banana sales vs received')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets look at all of our curves at the same time. Which one do we think looks most accurate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_data(figsize=(20,10))\n",
    "plt.plot(vizx, ylight, c='red', label='light regularization')\n",
    "plt.plot(vizx, ystrong, c='purple', label='strong regularization')\n",
    "plt.plot(vizx, ymed, c='blue', label='medium regularization')\n",
    "plt.xlim(x.min() - buffer, x.max() + buffer)\n",
    "plt.ylim(y.min() - buffer * 2, y.max() + buffer * 2)\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(imgdir, 'allreg.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO. So we visualized some of our models to get intuition for what regularization is doing.\n",
    "# But what about quantitatively measure the differences.\n",
    "# Which models hit the datapoints best above?\n",
    "# Which models do you think with validate the best?\n",
    "# lets validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "NUM_DATA_VALIDATE = 20\n",
    "x = np.random.randint(20, 50, size=(NUM_DATA_VALIDATE, 1))\n",
    "y = get_y(x)\n",
    "x_train, x_test, y_train, y_test = # Split dataset into train and test with a 50%50 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_features, x_test_features = # TODO: Extract polynomial features with PolynomialFeatures(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = {}\n",
    "for reg in [100, 1., 1e-5, 1e-20]:\n",
    "    \n",
    "    mdl = ## TODO: Train a model with regularizatio reg\n",
    "    yhat = # make predictions on x_test_features\n",
    "    error = # Calculate your error\n",
    "    errors[reg] = error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which regularization strength performed the best?\n",
    "pd.Series(errors).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "errors = {}\n",
    "plot_data(figsize=(20,10))\n",
    "\n",
    "lry = lr.predict(vizx)\n",
    "for reg in [100, 1., 1e-5, 1e-20]:\n",
    "    mdl = # Train a model\n",
    "    yhat = # make predictions\n",
    "    error = # Calculate the error\n",
    "    errors[reg] = error\n",
    "    yhatvix = # make predictions from the granular dataset for visualization\n",
    "    plt.plot(vizx, yhatvix, label=reg)\n",
    "plt.xlim(x.min() - buffer, x.max() + buffer)\n",
    "plt.ylim(y.min() - buffer * 2, y.max() + buffer * 2)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
